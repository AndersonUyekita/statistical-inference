`Week 1` Statistical Inference
================

-   👨🏻‍💻 Author: Anderson H Uyekita
-   📚 Specialization: <a
    href="https://www.coursera.org/specializations/data-science-statistics-machine-learning"
    target="_blank" rel="noopener">Data Science: Statistics and Machine
    Learning Specialization</a>
-   📖 Course:
    <a href="https://www.coursera.org/learn/statistical-inference"
    target="_blank" rel="noopener">Statistical Inference</a>
    -   🧑‍🏫 Instructor: Brian Caffo
-   📆 Week 1
    -   🚦 Start: Wednesday, 29 June 2022
    -   🏁 Finish: Thursday, 30 June 2022

------------------------------------------------------------------------

#### Assignments & Deliverables

-   [📝 Quiz 1](./quiz-1_statistical-inference.md)

#### Slides

-   Module 1 – Introductory video
-   Module 2 – Probability
-   Module 3 – Conditional probability
-   Module 4 – Expected values

#### Description

This week, we’ll focus on the fundamentals including probability, random
variables, expectations and more.

------------------------------------------------------------------------

## Class Notes

All notes in this document were extracted from the class slides or the
course book.

### Module 1 – Introductory video

Statistical Inference Definitions:

> -   The process of generating conclusions about a population from a
>     noisy sample.
> -   Statistical inference is the process of drawing formal conclusions
>     from data.

### Module 2 – Probability

> In this module we discuss probability, the foundation of statistical
> analysis. Probability assigns a number between 0 and 1 to events to
> give a sense of the “chance” of the event. Probability has become our
> default model for apparently random phenomena. Our eventual goal is to
> use probability models, our formal mechanism for connecting our data
> to a population. However, before we get to probability models, we need
> to understand the basics of probability calculus. The next few
> lectures cover these basics.

**Statistical inference defined**

> We’ll define statistical inference as the process of generating
> conclusions about a population from a noisy sample.

-   Probability models will serve as our parsimonious description of the
    world
-   The use of probability models as the connection between our data and
    a populations represents **the most effective way to obtain
    inference**.

**The goals of inference**

Here we list five examples of inferential goals:

1.  Estimate and quantify the uncertainty of an estimate of a population
    quantity (the proportion of people who will vote for a candidate).
2.  Determine whether a population quantity is a benchmark value (“is
    the treatment effective?”).
3.  Infer a mechanistic relationship when quantities are measured with
    noise (“What is the slope for Hooke’s law?”)
4.  Determine the impact of a policy? (“If we reduce pollution levels,
    will asthma rates decline?”)
5.  Talk about the probability that something occurs.

**The tools of the trade**

1.  Randomization: concerned with balancing unobserved variables that
    may confound inferences of interest.
2.  Random sampling: concerned with obtaining data that is
    representative of the population of interest.
3.  Sampling models: concerned with creating a model for the sampling
    process, the most common is so called “iid”.
4.  Hypothesis testing: concerned with decision making in the presence
    of uncertainty.
5.  Confidence intervals: concerned with quantifying uncertainty in
    estimation.
6.  Probability models: a formal connection between the data and a
    population of interest. Often probability models are assumed or are
    approximated.
7.  Study design: the process of designing an experiment to minimize
    biases and variability.
8.  Nonparametric bootstrapping: the process of using the data to, with
    minimal probability model assumptions, create inferences.
9.  Permutation, randomization and exchangeability testing: the process
    of using data permutations to perform inferences.
