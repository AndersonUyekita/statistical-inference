---
title: '`Week 1` Statistical Inference'
author: '`r if(knitr::is_html_output()) {"&#x1f468;&#x1F3FB;&#x200d;&#x1f4bb; Anderson H Uyekita"} else {NULL}`'
output:
  github_document: default
params:
  author: 'Anderson H Uyekita'
  course: 'Statistical Inference'
  course_url: 'https://www.coursera.org/learn/statistical-inference'
  specialization: 'Data Science: Statistics and Machine Learning Specialization'
  specialization_url: 'https://www.coursera.org/specializations/data-science-statistics-machine-learning'
  instructor: 'Brian Caffo'
  course_start: !r lubridate::ymd('2022/06/29', tz = "America/Sao_Paulo")
  course_finish: !r lubridate::ymd('2022/06/30', tz = "America/Sao_Paulo")
  week: ' Week 1'
---

```{r setup,include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE, message = FALSE, warning = FALSE)
library(rmarkdown)
library(lubridate)
```

`r if(!knitr::is_html_output()) {sprintf(fmt = "* &#x1f468;&#x1F3FB;&#x200d;&#x1f4bb; Author: %s", params$author)}`
`r sprintf(fmt = "* &#x1f4da; Specialization: [%s](%s){target='_blank' rel='noopener'}", params$specialization, params$specialization_url)`
`r sprintf(fmt = "* &#x1f4d6; Course: [%s](%s){target='_blank' rel='noopener'}", params$course, params$course_url)`
    `r sprintf(fmt = "* &#x1F9D1;&#x200d;&#x1F3EB; Instructor: %s", params$instructor)`
`r sprintf(fmt = "* &#x1F4C6; %s", params$week)`
    `r sprintf(fmt = "* &#x1F6A6; Start: %s", format(params$course_start, "%A, %d %B %Y"))`
    `r sprintf(fmt = "* &#x1F3C1; Finish: %s", format(params$course_finish, "%A, %d %B %Y"))`

--------------------------------------------------------------------------------

#### Assignments & Deliverables

* [&#x1F4DD; Quiz 1](./quiz-1_statistical-inference.md)

#### Slides

* Module 1 -- Introductory video
* Module 2 -- Probability
* Module 3 -- Conditional probability
* Module 4 -- Expected values

#### Description

This week, we'll focus on the fundamentals including probability, random variables, expectations and more.

--------------------------------------------------------------------------------

## Class Notes

All notes in this document were extracted from the class slides or the course book.

### Module 1 -- Introductory video

Statistical Inference Definitions:

> * The process of generating conclusions about a population from a noisy sample.
> * Statistical inference is the process of drawing formal conclusions from data.

### Module 2 -- Probability

> In this module we discuss probability, the foundation of statistical analysis. Probability assigns a number between 0 and 1 to events to give a sense of the "chance" of the event. Probability has become our default model for apparently random phenomena. Our eventual goal is to use probability models, our formal mechanism for connecting our data to a population. However, before we get to probability models, we need to understand the basics of probability calculus. The next few lectures cover these basics.

**Statistical inference defined**

>We’ll define statistical inference as the process of generating conclusions about a population from a noisy sample.

* Probability models will serve as our parsimonious description of the world
* The use of probability models as the connection between our data and a populations represents **the most effective way to obtain inference**.

**The goals of inference**

Here we list five examples of inferential goals:

1. Estimate and quantify the uncertainty of an estimate of a population quantity (the proportion of people who will vote for a candidate).
2. Determine whether a population quantity is a benchmark value (“is the treatment effective?”).
3. Infer a mechanistic relationship when quantities are measured with noise (“What is the slope for Hooke’s law?”)
4. Determine the impact of a policy? (“If we reduce pollution levels, will asthma rates decline?”)
5. Talk about the probability that something occurs.

**The tools of the trade**

1. Randomization: concerned with balancing unobserved variables that may confound inferences of interest.
2. Random sampling: concerned with obtaining data that is representative of the population of
interest.
3. Sampling models: concerned with creating a model for the sampling process, the most common
is so called “iid”.
4. Hypothesis testing: concerned with decision making in the presence of uncertainty.
5. Confidence intervals: concerned with quantifying uncertainty in estimation.
6. Probability models: a formal connection between the data and a population of interest. Often
probability models are assumed or are approximated.
7. Study design: the process of designing an experiment to minimize biases and variability.
8. Nonparametric bootstrapping: the process of using the data to, with minimal probability
model assumptions, create inferences.
9. Permutation, randomization and exchangeability testing: the process of using data permutations to perform inferences.